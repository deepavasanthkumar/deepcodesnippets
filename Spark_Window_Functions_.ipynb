{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spark Window Functions .ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNRgBhDBHLFpc/rzBqa/xGI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deepavasanthkumar/deepcodesnippets/blob/master/Spark_Window_Functions_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5wDgv2wKP4n",
        "outputId": "945b2971-2058-407d-d22d-853e2ff5e2b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.2.1.tar.gz (281.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.4 MB 35 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.3\n",
            "  Downloading py4j-0.10.9.3-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 50.2 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.2.1-py2.py3-none-any.whl size=281853642 sha256=ebc56aff744af91c761228e73175d67382801137289cf3adf8c4b6fb4c1d730f\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/f5/07/7cd8017084dce4e93e84e92efd1e1d5334db05f2e83bcef74f\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.3 pyspark-3.2.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "  \n",
        "spark = SparkSession.builder.appName(\"Spark Window Functions \").getOrCreate()\n",
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "C_rzbBtfKaQD",
        "outputId": "5db17b36-a92a-43aa-fd07-76ad06c62990"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f16fb225710>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://e7adc75e6072:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.2.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Spark Window Functions </code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import StructType,StructField, StringType, IntegerType\n",
        "data1 = [(\"James\",\"\",\"Smith\",\"36636\",\"M\", 1000, \"Sales\", 2020),\n",
        "    (\"Michael\",\"Rose\",\"\",\"40288\",\"M\", 2000, \"Operations\",2020),\n",
        "    (\"Robert\",\"\",\"Williams\",\"42114\",\"M\", 3000, \"Sales\",2020),\n",
        "    (\"Maria\",\"Anne\",\"Jones\",\"39192\",\"F\", 4000, \"Operations\",2020),\n",
        "    (\"James\",\"\",\"Smith\",\"36636\",\"M\", 1050, \"Sales\", 2021),\n",
        "    (\"Michael\",\"Rose\",\"\",\"40288\",\"M\", 1950, \"Operations\",2021),\n",
        "    (\"Robert\",\"\",\"Williams\",\"42114\",\"M\", 3100, \"Sales\",2021),\n",
        "    (\"Maria\",\"Anne\",\"Jones\",\"39192\",\"F\", 4200, \"Operations\",2021),\n",
        "     (\"James\",\"\",\"Smith\",\"36636\",\"M\", 1050, \"Sales\", 2017),\n",
        "    (\"Michael\",\"Rose\",\"\",\"40288\",\"M\", 1950, \"Operations\",2017),\n",
        "    (\"Robert\",\"\",\"Williams\",\"42114\",\"M\", 3100, \"Sales\",2017),\n",
        "    (\"Maria\",\"Anne\",\"Jones\",\"39192\",\"F\", 4200, \"Operations\",2017),\n",
        "    (\"James\",\"\",\"Smith\",\"36636\",\"M\", 990, \"Sales\", 2019),\n",
        "    (\"Michael\",\"Rose\",\"\",\"40288\",\"M\", 2200, \"Operations\",2019),\n",
        "    (\"Robert\",\"\",\"Williams\",\"42114\",\"M\", 2900, \"Sales\",2019),\n",
        "    (\"Maria\",\"Anne\",\"Jones\",\"39192\",\"F\", 4500, \"Operations\",2019)\n",
        "\n",
        " \n",
        "  \n",
        "  ]\n",
        "\n",
        "schema1 = StructType([ \\\n",
        "    StructField(\"firstname\",StringType(),True), \\\n",
        "    StructField(\"middlename\",StringType(),True), \\\n",
        "    StructField(\"lastname\",StringType(),True), \\\n",
        "    StructField(\"id\", StringType(), True), \\\n",
        "    StructField(\"gender\", StringType(), True),\n",
        "    StructField(\"annualsalary\", IntegerType(), True),\n",
        "    StructField(\"work\", StringType(), True),\n",
        "    StructField(\"year\", IntegerType(), True),\n",
        "   \n",
        "  ])\n",
        " \n",
        "df1 = spark.createDataFrame(data=data1,schema=schema1)\n",
        "df1.printSchema()\n",
        "df1.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fWa75d-Mxdm",
        "outputId": "15752a21-af8b-4cf8-a960-68082982e1a3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- firstname: string (nullable = true)\n",
            " |-- middlename: string (nullable = true)\n",
            " |-- lastname: string (nullable = true)\n",
            " |-- id: string (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- annualsalary: integer (nullable = true)\n",
            " |-- work: string (nullable = true)\n",
            " |-- year: integer (nullable = true)\n",
            "\n",
            "+---------+----------+--------+-----+------+------------+----------+----+\n",
            "|firstname|middlename|lastname|id   |gender|annualsalary|work      |year|\n",
            "+---------+----------+--------+-----+------+------------+----------+----+\n",
            "|James    |          |Smith   |36636|M     |1000        |Sales     |2020|\n",
            "|Michael  |Rose      |        |40288|M     |2000        |Operations|2020|\n",
            "|Robert   |          |Williams|42114|M     |3000        |Sales     |2020|\n",
            "|Maria    |Anne      |Jones   |39192|F     |4000        |Operations|2020|\n",
            "|James    |          |Smith   |36636|M     |1050        |Sales     |2021|\n",
            "|Michael  |Rose      |        |40288|M     |1950        |Operations|2021|\n",
            "|Robert   |          |Williams|42114|M     |3100        |Sales     |2021|\n",
            "|Maria    |Anne      |Jones   |39192|F     |4200        |Operations|2021|\n",
            "|James    |          |Smith   |36636|M     |1050        |Sales     |2017|\n",
            "|Michael  |Rose      |        |40288|M     |1950        |Operations|2017|\n",
            "|Robert   |          |Williams|42114|M     |3100        |Sales     |2017|\n",
            "|Maria    |Anne      |Jones   |39192|F     |4200        |Operations|2017|\n",
            "|James    |          |Smith   |36636|M     |990         |Sales     |2019|\n",
            "|Michael  |Rose      |        |40288|M     |2200        |Operations|2019|\n",
            "|Robert   |          |Williams|42114|M     |2900        |Sales     |2019|\n",
            "|Maria    |Anne      |Jones   |39192|F     |4500        |Operations|2019|\n",
            "+---------+----------+--------+-----+------+------------+----------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import row_number\n",
        "windowSpec  = Window.partitionBy(\"work\").orderBy(\"annualsalary\")"
      ],
      "metadata": {
        "id": "Wxh9YXhcfQzv"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Rank Function "
      ],
      "metadata": {
        "id": "X9nIZMSXfBuy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "rank() window function is used to provide a rank to the result within a window partition. This function leaves gaps in rank when there are ties."
      ],
      "metadata": {
        "id": "V5jnht9CfHyk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "fTvOHexQgMbb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The difference between **rank** and **dense_rank** is that denseRank leaves no gaps in ranking sequence when there are ties. That is, if you were ranking a competition using dense_rank and had three people tie for second place, you would say that all three were in second place and that the next person came in third. Rank would give me sequential numbers, making the person that came in third place (after the ties) would register as coming in fifth."
      ],
      "metadata": {
        "id": "TlowIeDdgMOa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Gb5_5W-IgYCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import rank\n",
        "df1.withColumn(\"rank\",rank().over(windowSpec)).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXuaYpu-fFbp",
        "outputId": "f3d649f1-f7b4-48ef-e433-0ee46f056817"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----------+--------+-----+------+------------+----------+----+----+\n",
            "|firstname|middlename|lastname|   id|gender|annualsalary|      work|year|rank|\n",
            "+---------+----------+--------+-----+------+------------+----------+----+----+\n",
            "|  Michael|      Rose|        |40288|     M|        1950|Operations|2021|   1|\n",
            "|  Michael|      Rose|        |40288|     M|        1950|Operations|2017|   1|\n",
            "|  Michael|      Rose|        |40288|     M|        2000|Operations|2020|   3|\n",
            "|  Michael|      Rose|        |40288|     M|        2200|Operations|2019|   4|\n",
            "|    Maria|      Anne|   Jones|39192|     F|        4000|Operations|2020|   5|\n",
            "|    Maria|      Anne|   Jones|39192|     F|        4200|Operations|2021|   6|\n",
            "|    Maria|      Anne|   Jones|39192|     F|        4200|Operations|2017|   6|\n",
            "|    Maria|      Anne|   Jones|39192|     F|        4500|Operations|2019|   8|\n",
            "|    James|          |   Smith|36636|     M|         990|     Sales|2019|   1|\n",
            "|    James|          |   Smith|36636|     M|        1000|     Sales|2020|   2|\n",
            "|    James|          |   Smith|36636|     M|        1050|     Sales|2021|   3|\n",
            "|    James|          |   Smith|36636|     M|        1050|     Sales|2017|   3|\n",
            "|   Robert|          |Williams|42114|     M|        2900|     Sales|2019|   5|\n",
            "|   Robert|          |Williams|42114|     M|        3000|     Sales|2020|   6|\n",
            "|   Robert|          |Williams|42114|     M|        3100|     Sales|2021|   7|\n",
            "|   Robert|          |Williams|42114|     M|        3100|     Sales|2017|   7|\n",
            "+---------+----------+--------+-----+------+------------+----------+----+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import dense_rank\n",
        "df1.withColumn(\"dense_rank\",dense_rank().over(windowSpec)).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqga9ySigluF",
        "outputId": "f9ea9a2c-2038-463f-8e98-4336d091eb85"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----------+--------+-----+------+------------+----------+----+----------+\n",
            "|firstname|middlename|lastname|   id|gender|annualsalary|      work|year|dense_rank|\n",
            "+---------+----------+--------+-----+------+------------+----------+----+----------+\n",
            "|  Michael|      Rose|        |40288|     M|        1950|Operations|2021|         1|\n",
            "|  Michael|      Rose|        |40288|     M|        1950|Operations|2017|         1|\n",
            "|  Michael|      Rose|        |40288|     M|        2000|Operations|2020|         2|\n",
            "|  Michael|      Rose|        |40288|     M|        2200|Operations|2019|         3|\n",
            "|    Maria|      Anne|   Jones|39192|     F|        4000|Operations|2020|         4|\n",
            "|    Maria|      Anne|   Jones|39192|     F|        4200|Operations|2021|         5|\n",
            "|    Maria|      Anne|   Jones|39192|     F|        4200|Operations|2017|         5|\n",
            "|    Maria|      Anne|   Jones|39192|     F|        4500|Operations|2019|         6|\n",
            "|    James|          |   Smith|36636|     M|         990|     Sales|2019|         1|\n",
            "|    James|          |   Smith|36636|     M|        1000|     Sales|2020|         2|\n",
            "|    James|          |   Smith|36636|     M|        1050|     Sales|2021|         3|\n",
            "|    James|          |   Smith|36636|     M|        1050|     Sales|2017|         3|\n",
            "|   Robert|          |Williams|42114|     M|        2900|     Sales|2019|         4|\n",
            "|   Robert|          |Williams|42114|     M|        3000|     Sales|2020|         5|\n",
            "|   Robert|          |Williams|42114|     M|        3100|     Sales|2021|         6|\n",
            "|   Robert|          |Williams|42114|     M|        3100|     Sales|2017|         6|\n",
            "+---------+----------+--------+-----+------+------------+----------+----+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "lnFv3fiJglec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Percent Rank"
      ],
      "metadata": {
        "id": "sLUY2dyVfpkl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import percent_rank\n",
        "df1.withColumn(\"percent_rank\",percent_rank().over(windowSpec)) \\\n",
        "    .show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2TbHSx4fsco",
        "outputId": "3f39b533-640e-442f-d831-2cddc005aee9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----------+--------+-----+------+------------+----------+----+-------------------+\n",
            "|firstname|middlename|lastname|   id|gender|annualsalary|      work|year|       percent_rank|\n",
            "+---------+----------+--------+-----+------+------------+----------+----+-------------------+\n",
            "|  Michael|      Rose|        |40288|     M|        1950|Operations|2021|                0.0|\n",
            "|  Michael|      Rose|        |40288|     M|        1950|Operations|2017|                0.0|\n",
            "|  Michael|      Rose|        |40288|     M|        2000|Operations|2020| 0.2857142857142857|\n",
            "|  Michael|      Rose|        |40288|     M|        2200|Operations|2019|0.42857142857142855|\n",
            "|    Maria|      Anne|   Jones|39192|     F|        4000|Operations|2020| 0.5714285714285714|\n",
            "|    Maria|      Anne|   Jones|39192|     F|        4200|Operations|2021| 0.7142857142857143|\n",
            "|    Maria|      Anne|   Jones|39192|     F|        4200|Operations|2017| 0.7142857142857143|\n",
            "|    Maria|      Anne|   Jones|39192|     F|        4500|Operations|2019|                1.0|\n",
            "|    James|          |   Smith|36636|     M|         990|     Sales|2019|                0.0|\n",
            "|    James|          |   Smith|36636|     M|        1000|     Sales|2020|0.14285714285714285|\n",
            "|    James|          |   Smith|36636|     M|        1050|     Sales|2021| 0.2857142857142857|\n",
            "|    James|          |   Smith|36636|     M|        1050|     Sales|2017| 0.2857142857142857|\n",
            "|   Robert|          |Williams|42114|     M|        2900|     Sales|2019| 0.5714285714285714|\n",
            "|   Robert|          |Williams|42114|     M|        3000|     Sales|2020| 0.7142857142857143|\n",
            "|   Robert|          |Williams|42114|     M|        3100|     Sales|2021| 0.8571428571428571|\n",
            "|   Robert|          |Williams|42114|     M|        3100|     Sales|2017| 0.8571428571428571|\n",
            "+---------+----------+--------+-----+------+------------+----------+----+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# row_number Window Function\n",
        "\n",
        "returns a sequential number starting at 1 within a window partition.\n"
      ],
      "metadata": {
        "id": "vqXCRQ4SdgDT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "df1.withColumn(\"row_number\",row_number().over(windowSpec)) \\\n",
        "    .show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4_3iM6Bdtkd",
        "outputId": "ee00c831-c295-4a0a-c31c-e18b59c53850"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----------+--------+-----+------+------------+----------+----+----------+\n",
            "|firstname|middlename|lastname|id   |gender|annualsalary|work      |year|row_number|\n",
            "+---------+----------+--------+-----+------+------------+----------+----+----------+\n",
            "|Michael  |Rose      |        |40288|M     |1950        |Operations|2021|1         |\n",
            "|Michael  |Rose      |        |40288|M     |1950        |Operations|2017|2         |\n",
            "|Michael  |Rose      |        |40288|M     |2000        |Operations|2020|3         |\n",
            "|Michael  |Rose      |        |40288|M     |2200        |Operations|2019|4         |\n",
            "|Maria    |Anne      |Jones   |39192|F     |4000        |Operations|2020|5         |\n",
            "|Maria    |Anne      |Jones   |39192|F     |4200        |Operations|2021|6         |\n",
            "|Maria    |Anne      |Jones   |39192|F     |4200        |Operations|2017|7         |\n",
            "|Maria    |Anne      |Jones   |39192|F     |4500        |Operations|2019|8         |\n",
            "|James    |          |Smith   |36636|M     |990         |Sales     |2019|1         |\n",
            "|James    |          |Smith   |36636|M     |1000        |Sales     |2020|2         |\n",
            "|James    |          |Smith   |36636|M     |1050        |Sales     |2021|3         |\n",
            "|James    |          |Smith   |36636|M     |1050        |Sales     |2017|4         |\n",
            "|Robert   |          |Williams|42114|M     |2900        |Sales     |2019|5         |\n",
            "|Robert   |          |Williams|42114|M     |3000        |Sales     |2020|6         |\n",
            "|Robert   |          |Williams|42114|M     |3100        |Sales     |2021|7         |\n",
            "|Robert   |          |Williams|42114|M     |3100        |Sales     |2017|8         |\n",
            "+---------+----------+--------+-----+------+------------+----------+----+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analytical Window Functions - Lag & Lead"
      ],
      "metadata": {
        "id": "2PONrFBFhk_j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lag** Window function: returns the value that is `offset` rows before the current row, and 'null` if there is less than `offset` rows before the current row. For example, \n",
        "   * an `offset` of one will return the previous row at any given point in the window partition."
      ],
      "metadata": {
        "id": "c1KXaClPjFoC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import lag\n",
        "windowYear  = Window.partitionBy(\"id\").orderBy(\"year\")\n",
        " \n",
        "df1 = df1.withColumn(\"PreviousYearSalary\", lag(\"annualSalary\", 1).over(windowYear))\n",
        "df1.select(\"firstname\",\"year\",\"annualsalary\",\"PreviousYearSalary\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezr1oEkDhsPl",
        "outputId": "4d79ec14-e83e-4584-cd12-17108e510fc6"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----+------------+------------------+\n",
            "|firstname|year|annualsalary|PreviousYearSalary|\n",
            "+---------+----+------------+------------------+\n",
            "|    James|2017|        1050|              null|\n",
            "|    James|2019|         990|              1050|\n",
            "|    James|2020|        1000|               990|\n",
            "|    James|2021|        1050|              1000|\n",
            "|    Maria|2017|        4200|              null|\n",
            "|    Maria|2019|        4500|              4200|\n",
            "|    Maria|2020|        4000|              4500|\n",
            "|    Maria|2021|        4200|              4000|\n",
            "|  Michael|2017|        1950|              null|\n",
            "|  Michael|2019|        2200|              1950|\n",
            "|  Michael|2020|        2000|              2200|\n",
            "|  Michael|2021|        1950|              2000|\n",
            "|   Robert|2017|        3100|              null|\n",
            "|   Robert|2019|        2900|              3100|\n",
            "|   Robert|2020|        3000|              2900|\n",
            "|   Robert|2021|        3100|              3000|\n",
            "+---------+----+------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "   **Lead ** Window function: returns the value that is `offset` rows after the current row, and `null` if there is less than `offset` rows after the current row. For example,  an `offset` of one will return the next row at any given point in the window partition."
      ],
      "metadata": {
        "id": "vKgL7zJSjPlF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import lead\n",
        "windowYear  = Window.partitionBy(\"id\").orderBy(\"year\")\n",
        " \n",
        "df1 = df1.withColumn(\"NextYearSalary\", lead(\"annualSalary\", 1).over(windowYear))\n",
        "df1.select(\"firstname\",\"year\",\"PreviousYearSalary\",\"annualsalary\",\"NextYearSalary\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpciCjB7it4H",
        "outputId": "8bd0cc42-17d1-4dc9-d48c-4d0229f392d7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----+------------------+------------+--------------+\n",
            "|firstname|year|PreviousYearSalary|annualsalary|NextYearSalary|\n",
            "+---------+----+------------------+------------+--------------+\n",
            "|    James|2017|              null|        1050|           990|\n",
            "|    James|2019|              1050|         990|          1000|\n",
            "|    James|2020|               990|        1000|          1050|\n",
            "|    James|2021|              1000|        1050|          null|\n",
            "|    Maria|2017|              null|        4200|          4500|\n",
            "|    Maria|2019|              4200|        4500|          4000|\n",
            "|    Maria|2020|              4500|        4000|          4200|\n",
            "|    Maria|2021|              4000|        4200|          null|\n",
            "|  Michael|2017|              null|        1950|          2200|\n",
            "|  Michael|2019|              1950|        2200|          2000|\n",
            "|  Michael|2020|              2200|        2000|          1950|\n",
            "|  Michael|2021|              2000|        1950|          null|\n",
            "|   Robert|2017|              null|        3100|          2900|\n",
            "|   Robert|2019|              3100|        2900|          3000|\n",
            "|   Robert|2020|              2900|        3000|          3100|\n",
            "|   Robert|2021|              3000|        3100|          null|\n",
            "+---------+----+------------------+------------+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lag and Lead with negative offsets**\n",
        "\n"
      ],
      "metadata": {
        "id": "HvJbBwV3mihD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import lag, lead\n",
        "windowYear  = Window.partitionBy(\"id\").orderBy(\"year\")\n",
        " \n",
        "df1 = df1.withColumn(\"salary2\", lead(\"annualSalary\", -1).over(windowYear)) \n",
        "df1 = df1.withColumn(\"salary1\", lag(\"annualSalary\", -1).over(windowYear))\n",
        "df1.select(\"firstname\",\"year\",\"annualsalary\",\"salary2\", \"PreviousYearSalary\",\"salary1\", \"NextYearSalary\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEoF2KrJmKqH",
        "outputId": "62406ee1-484e-4903-e35a-7f55731b2e7b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----+------------+-------+------------------+-------+--------------+\n",
            "|firstname|year|annualsalary|salary2|PreviousYearSalary|salary1|NextYearSalary|\n",
            "+---------+----+------------+-------+------------------+-------+--------------+\n",
            "|    James|2017|        1050|   null|              null|    990|           990|\n",
            "|    James|2019|         990|   1050|              1050|   1000|          1000|\n",
            "|    James|2020|        1000|    990|               990|   1050|          1050|\n",
            "|    James|2021|        1050|   1000|              1000|   null|          null|\n",
            "|    Maria|2017|        4200|   null|              null|   4500|          4500|\n",
            "|    Maria|2019|        4500|   4200|              4200|   4000|          4000|\n",
            "|    Maria|2020|        4000|   4500|              4500|   4200|          4200|\n",
            "|    Maria|2021|        4200|   4000|              4000|   null|          null|\n",
            "|  Michael|2017|        1950|   null|              null|   2200|          2200|\n",
            "|  Michael|2019|        2200|   1950|              1950|   2000|          2000|\n",
            "|  Michael|2020|        2000|   2200|              2200|   1950|          1950|\n",
            "|  Michael|2021|        1950|   2000|              2000|   null|          null|\n",
            "|   Robert|2017|        3100|   null|              null|   2900|          2900|\n",
            "|   Robert|2019|        2900|   3100|              3100|   3000|          3000|\n",
            "|   Robert|2020|        3000|   2900|              2900|   3100|          3100|\n",
            "|   Robert|2021|        3100|   3000|              3000|   null|          null|\n",
            "+---------+----+------------+-------+------------------+-------+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Source Code for reference :\n",
        "https://github.com/apache/spark/blob/master/sql/core/src/main/scala/org/apache/spark/sql/functions.scala"
      ],
      "metadata": {
        "id": "QtM8wEx3jeav"
      }
    }
  ]
}